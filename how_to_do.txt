часто проблема ключевого параметра, по которому мы будем принимать
решение довольно остро стоит, или же метрики оценки, насколько хорошо
наша задача обучения работает без учителя

в случае кластеризации есть много методов, насколько кластеров
нам необходимо разбить наши данные, чтобы они были распределены
по примерно равномерным группам распределены

в случае ограничения нашего пространства признаков до нескольких
значащих, критерия правильности 5-ти признаков из 20-ти (правильной
пропоции/формы или же описывают наши данные правильным образом),
а все остальные 15 отбрасываем. мы ограничиваем кол-во признаков
характерными - кроме, как ограничить по размеру описываемой дисперсии
[сколько изменчивости нам определенное кол-во гарантирует - наиболее
влияющих/коррелирующих с результатом признаков] по ПРАВИЛУ ЛОКТЯ

Правило локтя
пусть по оси OY мы отложим дисперсию, т.е. кол-во информации (шума),
которая осталось необъяснимой после ограничения числа параметров,
то график будет таким,
каким его выводит plt.show() (строка 58 speechrecog.py)
правило локтя заключается в том, что мы берем то кол-во факторов
(кластеров), на котором у нас случается перегиб в уменьшении
дисперсии - перегиб от резкого спуска к выравниванию.
график функции - 1/x (обратная пропорциональность). так мы
определяем кол-во факторов, при котором мы не сильно потеряем
в объяснении целевой переменной

К-средних
1. Выбераем K случайных точек в качестве центров кластеров,
называемых центроидами.
2. Назначаем каждую точку данных ближайшему кластеру,
рассчитав ее расстояние относительно каждого центроида.
3. Определяем новый центр кластера, вычислив среднее значение
присвоенных точек.
4. Повторяем шаги 2 и 3, пока ни одно из назначений кластера не
изменится.
5*. Для выбора кол-ва кластеров Мы графически отображаем взаимосвязь
между количеством кластеров и суммой квадратов внутри кластера (WCSS),
затем выбираем количество кластеров, в которых изменение WCSS начинает
выравниваться (по методу локтя).
WCSS определяется как сумма квадратов расстояний
между каждым членом кластера и его центром тяжести.
Каждый раз сохраняя значение свойства intertia_(WCSS)
классифицируем данные, используя оптимальное количество кластеров (4),
которое мы определили на последнем шаге

stft. Преобразование Фурье
то же, что и дифференцирование, только работает с комплексными числами
отображая на графике, мы представляем комплексные числа в виде модуля
и аргумента и рисуем их по раздельности как два отдельных графика
https://habr.com/ru/articles/196374/
график аргумента комплексного значения - фазовый спектр, а график
модуля - амплитудный спектр.
логарифмы амплитуды при перемножении амплитуд складываются, поэтому
логарифмические графики амплитуды можно, как и графики фаз, просто
поточечно складывать

peak_find. Обнаружение шага
Существует хороший способ сделать спектр гармонического произведения
более устойчивым к воздействию шума. Мы генерируем синтетический
спектр, начиная с гистограммы интервалов пересечения нуля,
которая была «размазана» обратно в непрерывный сигнал с гауссовскими
пиками, применяя оценку плотности ядра. Затем результат может быть
передан через HPS для нахождения фундаментальной частоты.
Декоррелированные пересечения нуля, вызванные шумом, вызывают гораздо
меньше проблем, чем работа с HPS исходного сигнала.
https://www.youtube.com/watch?v=8jp3WxOCxN8&ab_channel=%D0%A6%D0%98%D0%A2%D0%9C%D0%AD%D0%BA%D1%81%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%82%D0%B0

StratifiedShuffleSplit. Перекрестная проверка
wiki
Перекрёстная прове́рка (кросс-проверка, кроссвалидация, скользящий
контроль; англ. cross-validation) — метод оценки аналитической модели
и её поведения на независимых данных. При оценке модели имеющиеся в
наличии данные разбиваются на k частей. Затем на k−1 частях данных
производится обучение модели, а оставшаяся часть данных используется
для тестирования. Процедура повторяется k раз; в итоге каждая из k
частей данных используется для тестирования. В результате получается
оценка эффективности выбранной модели с наиболее равномерным
использованием имеющихся данных.

https://scikit-learn.ru/3-1-cross-validation-evaluating-estimator-performance/
Изучение параметров функции прогнозирования и тестирование ее на одних
и тех же данных является методологической ошибкой:
модель, которая будет просто повторять метки образцов, которые она
только что увидела, будет иметь идеальную оценку, но пока не сможет
предсказать что-либо полезное. Такая ситуация называется переобучением.
Чтобы этого избежать, при проведении (контролируемого) эксперимента с
машинным обучением обычно используется часть имеющихся данных в виде
набора тестов X_test, y_test.

При оценке различных настроек («гиперпараметров») для оценщиков, таких
как Cнастройка, которая должна быть вручную установлена ​​для SVM, все
еще существует риск переобучения на тестовом наборе, поскольку
параметры можно настраивать до тех пор, пока оценщик не будет работать
оптимально. Таким образом, знания о наборе тестов могут «просочиться»
в модель, а показатели оценки больше не будут сообщать о
производительности обобщения. Чтобы решить эту проблему, еще одна часть
набора данных может быть представлена ​​как так называемый «набор для
проверки»: обучение продолжается на обучающем наборе, после чего
выполняется оценка на проверочном наборе, и когда эксперимент кажется
успешным, окончательную оценку можно провести на тестовом наборе.

Однако, разбивая доступные данные на три набора, мы резко сокращаем
количество выборок, которые можно использовать для обучения модели,
а результаты могут зависеть от конкретного случайного выбора для пары
наборов (обучение, проверка).

Решением этой проблемы является процедура перекрестной проверки
(cross-validation сокращенно CV). Набор тестов по-прежнему должен
храниться для окончательной оценки, но набор для проверки больше не
нужен при выполнении резюме. В базовом подходе, называемом k- кратным
CV, обучающая выборка разбивается на k меньших наборов.
Для каждой из k «фолдов» выполняется следующая процедура :

Модель обучается с использованием (k-1) слоев в качестве обучающих
данных;
Результирующая модель проверяется на оставшейся части данных
(т. е. она используется в качестве тестового набора для вычисления
показателя производительности, такого как точность).
Показатель производительности, сообщаемый k- фолд перекрестной
проверкой, тогда является средним из значений, вычисленных в цикле.
Этот подход может быть дорогостоящим в вычислительном отношении, но не
тратит слишком много данных (как в случае фиксации произвольного набора
проверки), что является основным преимуществом в таких задачах, как
обратный вывод, когда количество выборок очень мало.

работа модели в Machine Learning.
https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%83%D1%87%D0%B0%D1%8E%D1%89%D0%B8%D0%B9,_%D0%BF%D1%80%D0%BE%D0%B2%D0%B5%D1%80%D0%BE%D1%87%D0%BD%D1%8B%D0%B9_%D0%B8_%D1%82%D0%B5%D1%81%D1%82%D0%BE%D0%B2%D1%8B%D0%B9_%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D1%8B_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85
Обучающий набор данных
Изначально модель тренируются с помощью Обучающего набора данных,
который является набором примеров используемых для настройки
параметров
(например, веса соединений между нейронами в искусственных нейронных
сетях) модели.
На практике обучающий набор данных часто состоит из пар входного
вектора (или скаляра) и соответствующего выходного вектора (или
скаляра), где выходное значение обычно обозначается как цель (или
метка).
Модель обучается с помощью обучающего набора данных и производит
результат, который затем сравнивается с меткой, для каждого входного
вектора в обучающем наборе данных. Основываясь на результате сравнения
и характере используемого алгоритма машинного обучения, параметры
модели подстраиваются соответствующим образом.

Проверочный набор данных
Далее, обученная модель используется для прогнозирования ответов для
наблюдения с помощью второго набора данных, называемого проверочный
набор данных (validation data set).Проверочный набор данных
предоставляет непредвзятую оценку модели, обученной с помощью
обучающего набора данных, в тоже время подстраивая гиперпараметры
модели (например, число скрытых слоев и ширину слоев в нейронной
сети))

Тестовый набор данных
тестовый набор данных (test data set) — это набор данных
использующийся для непредвзятой оценки окончательной модели,
настроенной с помощью обучающего набора данных.
Если данные в тестовом наборе данных никогда не были использованы в
обучении (например, в перекрёстной проверке), тестовый набор данных
также называется удержанным набором данных (holdout data set).
В некоторой литературе термин «проверочный набор» иногда используется
вместо «тестового набора» (например, если изначальный набор данных был
разделен только на два набора, тестовый набор может называться
проверочным набором).

Принятие решения о размерах и стратегиях разделения набора данных на
обучающий, тестовый и проверочный наборы сильно зависит от проблемы и
имеющихся данных

Так, мы избегаем переобучения

Скрытая Марковская Модель (HMM)
Марковская цепь - это такая цепь событий, в которой следующее событие
не зависит от прошлых, кроме как через настоящее.
1 -> 2 -> 3
Вычислительная сложность упрощается за счет независимости событий
от прошлых.
HMM - некоторый граф из состояний, который нам не всегда известен
(поэтому она и скрытая). Часто известна структура графа, но
не известны параметры перехода между вершинами этого графа
Функции _forward и _backward способствуют переходам в следующее
и предыдущее (обратно) состояние, возможен переход в себя, поэтому
при двух точках рёбер - 4 шт.
На каждом ребре фиксируется вероятность

Цепь Маркова - набор состояний и переходов между ними.
Вероятность переходов однозначно определяется состоянием
Марковский процесс характеризуется матрицей вероятностей между этими переходами.
Сумма вероятностей переходов из каждого состояние равна 1

Обучение без учителя
Предположим, что данные обучающие данные содержат только S
последовательностей наблюдений длины T.
Без соответствующей последовательности состояний цель - изучить скрытую
марковскую модель.
Мы рассматриваем данные последовательности наблюдений как данные
наблюдения O, а данные последовательности состояний - как ненаблюдаемые
скрытые данные I. Тогда скрытая марковская модель фактически является
вероятностной моделью со скрытыми переменными

Алгоритм Баума-Велша
Алгоритм Баума-Велша (Baum-Welch) - это итерационный алгоритм,
используемый для оценки параметров скрытой марковской модели (HMM) на
основе наблюдаемых данных. Он является одним из методов обучения без
учителя, то есть не требует размеченных данных.

Алгоритм Баума-Велша состоит из двух основных шагов: прямого прохода
(forward pass) и обратного прохода (backward pass). На каждой итерации
алгоритма выполняются эти два шага, после чего пересчитываются
параметры модели. Алгоритм продолжается до тех пор, пока не будет
достигнуто условие сходимости.

Прямой проход (forward pass) заключается в вычислении вероятности
наблюдаемой последовательности при заданных параметрах модели. 
Для этого используется рекурсивная формула, которая вычисляет
вероятность наблюдения каждого состояния на каждом временном шаге.
На первом шаге вероятность наблюдения первого состояния равна начальной вероятности этого состояния, умноженной на вероятность наблюдения
первого символа. На следующих шагах вероятность наблюдения каждого
состояния вычисляется как сумма произведений вероятности перехода из
предыдущего состояния в текущее состояние, умноженной на вероятность
наблюдения текущего символа.

Обратный проход (backward pass) заключается в вычислении вероятности
наблюдаемой последовательности при заданных параметрах модели, начиная
с последнего временного шага и двигаясь в обратном направлении.
Для этого также используется рекурсивная формула, которая вычисляет
вероятность наблюдения каждого состояния на каждом временном шаге.
На последнем шаге вероятность наблюдения последнего состояния равна 1.
На предыдущих шагах вероятность наблюдения каждого состояния
вычисляется как сумма произведений вероятности перехода из текущего
состояния в следующее состояние, умноженной на вероятность наблюдения
следующего символа.

После выполнения прямого и обратного проходов вычисляются вероятности
переходов и вероятности наблюдения символов для каждого состояния.
Затем параметры модели пересчитываются на основе этих вероятностей.
Этот процесс повторяется до тех пор, пока не будет достигнуто условие
сходимости.

Алгоритм Баума-Велша требует задания начальных параметров модели,
таких как начальные вероятности состояний, вероятности переходов между
состояниями и вероятности наблюдения символов в каждом состоянии.
Эти параметры могут быть заданы случайным образом или на основе
предварительного анализа данных.

Применение алгоритма Баума-Велша в скрытой марковской модели машинного
обучения позволяет оценить параметры модели на основе наблюдаемых
данных без необходимости разметки данных. Это делает алгоритм Баума-
Велша полезным инструментом для решения задач, связанных с анализом
последовательностей, таких как распознавание речи, распознавание
образов и прогнозирование временных рядов.


